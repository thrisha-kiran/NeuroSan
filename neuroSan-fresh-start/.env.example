# .env example

# A sample .env file that can be used to run the web client.
# To use this file, copy it to the root of the project and rename it to .env.

# Hostname used by NeuroSan (default = localhost)
NEURO_SAN_SERVER_HOST="localhost"

# Type of connection used by NeuroSan
NEURO_SAN_SERVER_CONNECTION="http"

# Port used by NeuroSan for HTTP connections (default = 8080)
NEURO_SAN_SERVER_HTTP_PORT=8080


# Port used by NeuroSan Web Client (default = 5003)
NEURO_SAN_WEB_CLIENT_PORT=5003

# Local development logging configuration
AGENT_SERVICE_LOG_JSON=logging.json

# A thinking file is used to store the agent's thoughts and is used by the NeuroSan server
# to communicate with the agent.
# Path to the thinking file used by NeuroSan defaults to "/tmp/agent_thinking.txt" if
# you're on a macOS or Linux system.
# Change the path to "C:\\tmp\\agent_thinking.txt" if you are using Windows
THINKING_FILE="/tmp/agent_thinking.txt"

# Add your LLM Provider API keys here
# You can get your OpenAI API key from https://platform.openai.com/signup.
# After signing up, create a new API key in the API keys section in your profile.
OPENAI_API_KEY="YOUR_OPENAI_API_KEY"

# you can get your ANTHROPIC API key from https://console.anthropic.com/
ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY"

# you can get your Google Gemini API key from https://ai.google.dev/gemini-api/docs/api-key
GOOGLE_API_KEY="YOUR_GOOGLE_GEMINI_API_KEY"

# To use Amazon Bedrock models, you must have an AWS account.
# You can sign up at: https://signin.aws.amazon.com/signup?request_type=register
# Note: Amazon Bedrock is a paid service. Pricing details are available at: https://aws.amazon.com/bedrock/pricing/
AWS_ACCESS_KEY_ID="YOUR_AWS_ACCESS_KEY_ID"
AWS_SECRET_ACCESS_KEY="YOUR_AWS_SECRET_ACCESS_KEY"

# Azure OpenAI configs
# Please see https://github.com/cognizant-ai-lab/neuro-san-studio/blob/main/docs/user_guide.md#azureopenai for more detailed information.
# Set the following environment variables to connect to the Azure OpenAI API.
# See https://azure.microsoft.com/en-us/products/ai-services/openai-service/ for more information.
AZURE_OPENAI_ENDPOINT="https://<your base url>.openai.azure.com/"
OPENAI_API_VERSION="<your Azure OpenAI API version e.g. 2024-12-01-preview>"
AZURE_OPENAI_API_KEY="<your Azure OpenAI API key>"
AZURE_OPENAI_DEPLOYMENT_NAME="<Your Azure OpenAI deployment name>"
# NOTE: Neuro-San previously used OPENAI_API_KEY for both OpenAI and Azure OpenAI models.
# For compatibility, you may still set OPENAI_API_KEY, but AZURE_OPENAI_API_KEY is now preferred.
# OPENAI_API_KEY="<your Azure OpenAI API key>"

# # Set path to the AGENT_LLM_INFO_FILE if required
# AGENT_LLM_INFO_FILE="./llm_info.hocon"


# Intranet Agents With Tools environment variables
# For HCM API documentation refer to https://docs.oracle.com/en/cloud/saas/human-resources/25b/farws/index.html
MI_BASE_URL="https://<server>/<resource-path>"
MI_APP_URL="https://<server>/<resource-path>"
MI_INTRANET="https://<server>/<resource-path>"
MI_HCM="https://<server>/<resource-path>"
MI_ABSENCE_MANAGEMENT="https://<server>/<resource-path>"
MI_TRAVEL_AND_EXPENSE="https://<server>/<resource-path>"
MI_GSD="https://<server>/<resource-path>"

# Agentforce config
# Set the following environment variables to connect to the Agentforce API.
# See https://developer.salesforce.com/docs/einstein/genai/guide/agent-api-get-started.html for more information.
AGENTFORCE_MY_DOMAIN_URL="https://<DOMAIN_NAME>.my.salesforce.com"
AGENTFORCE_AGENT_ID="<AGENT_ID>"
AGENTFORCE_CLIENT_ID="<CLIENT_ID>"
AGENTFORCE_CLIENT_SECRET="<CLIENT_SECRET>"


# Agentspace config
# Set the following environment variables to connect to an Agentspace agent.
GOOGLE_APPLICATION_CREDENTIALS="<path to application_default_credentials.json obtained from the GCP account>"
SERVICE_ACCT_EMAIL="<registered Email ID for GCP>"
ENGINE_ID="<ID of the agentspace app>"
GCP_PROJECT_ID="<GCP project ID>"
GCP_LOCATION="<Location as in the GCP app>"

# Brave search config
BRAVE_API_KEY="YOUR_BRAVE_API_KEY"
BRAVE_URL="https://api.search.brave.com/res/v1/web/search?q="
BRAVE_TIMEOUT=30

# ServiceNow AI Agents config
# Set the following environment variables to connect to ServiceNow AI Agents.
# You need a ServiceNow instance with AI Agents enabled and Now Assist licensing.
# Users must have the sn_aia.admin role or equivalent permissions.
SERVICENOW_INSTANCE_URL="https://<your-instance>.service-now.com/"
SERVICENOW_USER="<your-servicenow-username>"
SERVICENOW_PWD="<your-servicenow-password>"
SERVICENOW_CALLER_EMAIL="<caller-email@yourcompany.com>"
SERVICENOW_GET_AGENTS_QUERY=""

# Optional: Additional ServiceNow user for testing
SERVICENOW_PERSONAL_USER="<alternate-username>"
SERVICENOW_PERSONAL_PWD="<alternate-password>"

# Phoenix AI Observability Plugin
# Enable Phoenix for monitoring and analyzing LLM interactions
# Install dependencies first: pip install -r plugins/phoenix/requirements.txt
# For more information see plugins/phoenix/README.md

# Required settings
PHOENIX_ENABLED=false
PHOENIX_AUTOSTART=false

# Optional settings (defaults shown)
# PHOENIX_HOST=127.0.0.1
# PHOENIX_PORT=6006
# PHOENIX_PROJECT_NAME=default
# OTEL_SERVICE_NAME=neuro-san-studio
# OTEL_SERVICE_VERSION=dev
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://localhost:6006/v1/traces


# Rich Logging Bridge
LOGBRIDGE_ENABLED=true
